{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From H:\\Coding\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.normalization import local_response_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "max_document_length = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 将每个文件处理成为字符串的形式.\n",
    "\n",
    "def load_one_file(filename):\n",
    "    res = \"\"\n",
    "    with open(filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('\\r')\n",
    "            res += line\n",
    "    return res\n",
    "\n",
    "# 遍历6个文件夹并加载数据.\n",
    "\n",
    "def load_files_from_dir(rootdir):\n",
    "    res = []\n",
    "    list_ = os.listdir(rootdir)\n",
    "    for i in range(0, len(list_)):\n",
    "        path_ = os.path.join(rootdir, list_[i])\n",
    "        if os.path.isfile(path_):\n",
    "            v = load_one_file(path_)\n",
    "            res.append(v)\n",
    "    return res\n",
    "\n",
    "# 加载所有文件. 将正常邮件与垃圾邮件分别存储与ham与spam.\n",
    "\n",
    "def load_all_files():\n",
    "    ham = []\n",
    "    spam = []\n",
    "    for i in range(1,7):\n",
    "        path_ham = \"F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron%d/ham\" % i\n",
    "        print(\"Loading %s\" % path_ham)\n",
    "        ham += load_files_from_dir(path_ham)\n",
    "\n",
    "        path_spam = \"F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron%d/spam/\" % i\n",
    "        print(\"Loading %s\" % path_spam)\n",
    "        spam += load_files_from_dir(path_spam)\n",
    "    return ham, spam"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 用词袋模型将文本向量化.\n",
    "# ham 标记为0, spam 标记为1.\n",
    "\n",
    "def get_features_by_wording():\n",
    "    ham, spam = load_all_files()\n",
    "    X = ham + spam\n",
    "    Y = [0]*len(ham) + [1]*len(spam)\n",
    "    vectorizer = CountVectorizer(decode_error='ignore',\n",
    "                                 strip_accents='ascii',\n",
    "                                 max_features=max_features,\n",
    "                                 stop_words='english',\n",
    "                                 max_df=1.0,\n",
    "                                 min_df=1)\n",
    "    print(vectorizer)\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    X = X.toarray()\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 构建贝叶斯模型.\n",
    "\n",
    "def naivebaysian_wordbag(X_train, X_test, Y_train, Y_test):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    Y_pred = gnb.predict(X_test)\n",
    "    print(metrics.accuracy_score(Y_test, Y_pred))\n",
    "    print(metrics.confusion_matrix(Y_test, Y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron1/ham\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron1/spam/\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron2/ham\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron2/spam/\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron3/ham\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron3/spam/\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron4/ham\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron4/spam/\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron5/ham\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron5/spam/\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron6/ham\n",
      "Loading F:/复旦大学/课程（部分）/研一秋/机器学习与神经网络导论/期末试题/Q9_spam/data/enron6/spam/\n",
      "CountVectorizer(decode_error='ignore', max_features=5000, stop_words='english',\n",
      "                strip_accents='ascii')\n",
      "0.9432787128345814\n",
      "[[5937  632]\n",
      " [ 133 6785]]\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_features_by_wording()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "naivebaysian_wordbag(X_train, X_test, Y_train, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}